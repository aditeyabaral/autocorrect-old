{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim.downloader as api\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "stopw = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    temp = \"\"\n",
    "    for i in text.split():\n",
    "        try:\n",
    "            temp+=contraction[i]+' '\n",
    "        except:\n",
    "            temp+= i+' '\n",
    "    text = temp.strip()\n",
    "    text = text.lower().translate(remove_punctuation_map)\n",
    "    text = re.sub(\"[^a-zA-Z#]\",\" \",text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\",\", \"\", text)\n",
    "    text = re.sub(r\"\\.\", \"\", text)\n",
    "    text = re.sub(r\"!\", \"!\", text)\n",
    "    text = re.sub(r\"\\/\", \"\", text)\n",
    "    text = re.sub(r\"'\", \"\", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \":\", text)\n",
    "    text = re.sub(r' +',' ',text)\n",
    "    return text.strip()\n",
    "\n",
    "def stopwordremoval(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = [i for i in text if i not in stopw]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Machine learning is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult to develop a conventional algorithm for effectively performing the task.\"\"\"\n",
    "alt = \"\"\" Machine learning is the  study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult to develop a conventional algorithm for effectively performing the task.\"\"\"\n",
    "text2 = word_tokenize(text.lower().translate(remove_punctuation_map))\n",
    "text2 = [i for i in text2 if i not in stopw]\n",
    "alt2 = word_tokenize(alt.lower().translate(remove_punctuation_map))\n",
    "alt2 = [i for i in alt2 if i not in stopw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, smart_open\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            print(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "                \n",
    "def read_corpus_semeval(tokens_only=False):\n",
    "    i = 0\n",
    "    doc = api.load(\"semeval-2016-2017-task3-subtaskA-unannotated\")\n",
    "    for dictionary in doc:\n",
    "        sentList = []\n",
    "        for com in dictionary[\"RelComments\"]:\n",
    "            sentList.append(word_tokenize(clean(com[\"RelCText\"])))\n",
    "        sentList.append(word_tokenize(clean(dictionary[\"RelQuestion\"][\"RelQBody\"])))\n",
    "        for sent in sentList:\n",
    "            if tokens_only:\n",
    "                yield sent\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(sent, [i])\n",
    "                i += 1\n",
    "\n",
    "def read_fakenews(tokens_only=False):\n",
    "    doc = api.load(\"fake-news\")\n",
    "    i = 0\n",
    "    for line in doc: \n",
    "        dictionary = eval(json.dumps(line))\n",
    "        q = word_tokenize(clean(dictionary[\"title\"]))\n",
    "        t = [word_tokenize(clean(i)) for i in sent_tokenize(dictionary[\"text\"])]\n",
    "        t.append(q)\n",
    "        for sent in t:\n",
    "            if tokens_only:\n",
    "                yield sent\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(sent, [i])\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc1 = read_corpus_semeval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = Doc2Vec.load(\"dtv_semeval\")   \n",
    "except:\n",
    "    model = Doc2Vec(vector_size=300, workers=8, epochs=10)\n",
    "    model.build_vocab(tc1)\n",
    "    model.train(tc1, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dtv_semeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     model = Doc2Vec.load(\"dtv_semeval_text8\")\n",
    "# except:\n",
    "#     count = len(list(tc2))\n",
    "#     print(count)\n",
    "#     tc2 = read_corpus(api.load(\"text8\", return_path=True))\n",
    "#     model.build_vocab(tc2, update=True)\n",
    "#     model.train(tc2, total_examples=len(list(tc2)), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tc2 = read_corpus(api.load(\"text8\", return_path=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"dtv_semeval_text8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/miniconda3/envs/dotSlash2/lib/python3.7/site-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model = Doc2Vec.load(\"dtv_semeval_fn\")\n",
    "except:\n",
    "    tc3 = read_fakenews()\n",
    "    model.build_vocab(tc3, update=True)\n",
    "    model.train(tc3, total_examples=len(list(tc3)), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dtv_semeval_fn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598763"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.n_similarity(alt2, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
